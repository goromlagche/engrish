version: '3.8'

services:
  ollama:
    image: ollama/ollama:rocm
    container_name: ollama
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    environment:
      - HSA_OVERRIDE_GFX_VERSION=10.3.0
    volumes:
      - ollama:/root/.ollama
    networks:
      - ollama-network
    tty: true
    restart: unless-stopped
    entrypoint: >
      sh -c "
      echo 'ðŸ”„ Starting Ollama server...' &&
      nohup ollama serve > /tmp/ollama.log 2>&1 &

      echo 'â³ Waiting for Ollama API...' &&
      until ollama list > /dev/null 2>&1; do
        echo 'âŒ› Still waiting for Ollama...'
        sleep 2
      done

      echo 'ðŸ“¦ Pulling model: gpt-oss:20b' &&
      ollama pull gpt-oss:20b &&
      echo 'âœ… Model pulled! Now tailing server logs...' &&

      tail -f /tmp/ollama.log
      "

  writing-assistant:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: writing-assistant
    user: "${USER_ID:-1000}:${GROUP_ID:-1000}"
    stdin_open: true
    tty: true
    depends_on:
      - ollama
    environment:
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=gpt-oss:20b
    volumes:
      - /tmp:/tmp
    networks:
      - ollama-network
    restart: unless-stopped

volumes:
  ollama: {}

networks:
  ollama-network:
    driver: bridge
